{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import hydra\n",
    "import torch\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "from omegaconf import OmegaConf\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "project_root = Path(os.getcwd()).parent\n",
    "sys.path.append(str(project_root))\n",
    "\n",
    "# src import\n",
    "from utils import info as log_info\n",
    "from data import Preprocess, prepare_train_dataset, prepare_test_dataset\n",
    "from model import load_tokenizer_and_model_for_train, load_tokenizer_and_model_for_test\n",
    "from train import load_trainer_for_train\n",
    "from inference import inference\n",
    "from check_gpu import get_device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utils Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hydra 초기화 (노트북 환경에서 필요)\n",
    "hydra.core.global_hydra.GlobalHydra.instance().clear()\n",
    "hydra.initialize(config_path=\"../conf\", job_name=\"dialogue_summarization_notebook\")\n",
    "cfg = hydra.compose(config_name=\"config\") # 기본 설정 \n",
    "device = get_device() # GPU\n",
    "\n",
    "# 로드된 설정 확인\n",
    "log_info(OmegaConf.to_yaml(cfg))\n",
    "log_info(f\"PyTorch version: {torch.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 토크나이저 및 모델 로드 (학습용)\n",
    "log_info(\"Loading model and tokenizer for training...\")\n",
    "generate_model_train, tokenizer_train = load_tokenizer_and_model_for_train(cfg)\n",
    "\n",
    "# 데이터 준비 (학습용)\n",
    "log_info(\"Preparing training data...\")\n",
    "preprocessor_train = Preprocess(cfg.tokenizer.bos_token, cfg.tokenizer.eos_token)\n",
    "train_inputs_dataset, val_inputs_dataset = prepare_train_dataset(cfg, preprocessor_train, tokenizer_train)\n",
    "\n",
    "# 트레이너 로드 및 학습\n",
    "log_info(\"Starting model training...\")\n",
    "trainer = load_trainer_for_train(cfg, generate_model_train, tokenizer_train, train_inputs_dataset, val_inputs_dataset)\n",
    "trainer.train()\n",
    "\n",
    "# 모델 학습이 완료된 후 wandb를 종료합니다.\n",
    "# Jupyter 환경에서는 wandb.finish()를 명시적으로 호출하는 것이 좋습니다.\n",
    "import wandb\n",
    "use_wandb = os.getenv('USE_WANDB', '').lower() == 'true'\n",
    "if cfg.training.report_to == 'wandb' and use_wandb:\n",
    "    wandb.finish()\n",
    "\n",
    "log_info(\"Training complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_info(\"Starting inference...\")\n",
    "output_df = inference(cfg)\n",
    "log_info(\"Inference complete. Output saved to CSV.\")\n",
    "log_info(output_df.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "upstageailab-nlp-summarization-nlp-1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
